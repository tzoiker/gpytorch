{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is the simplest form of using an RBF kernel in an `VariationalGP` module for classification. This basic model is usable when there is not much training data and no advanced techniques are required.\n",
    "\n",
    "In this example, weâ€™re modeling a unit wave with period 1/2 centered with positive values @ x=0\n",
    "\n",
    "Variational inference uses the assumption that the posterior distribution factors multiplicatively over the input variables. This makes approximating the distribution via the KL divergence possible to obtain a fast approximation to the posterior. For a good explanation of variational techniques, sections 4-6 of the following may be useful: https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# Grid points are [0,1] every 1/9\n",
    "train_x = Variable(torch.linspace(0, 1, 10))\n",
    "# Labels are unit wave with period 1/2 centered with positive values @ x=0\n",
    "train_y = Variable(torch.sign(torch.cos(train_x.data * (4 * math.pi))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.priors import SmoothedBoxPrior\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood, BernoulliLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic classification model with variational inference\n",
    "class GPClassificationModel(gpytorch.models.VariationalGP):\n",
    "    def __init__(self, train_x):\n",
    "        super(GPClassificationModel, self).__init__(train_x)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = RBFKernel()\n",
    "        self.register_parameter(\n",
    "            name=\"log_outputscale\",\n",
    "            parameter=torch.nn.Parameter(torch.Tensor([0])),\n",
    "            prior=SmoothedBoxPrior(math.exp(-5), math.exp(6), sigma=0.1, log_transform=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x) * self.log_outputscale.exp()\n",
    "        latent_pred = GaussianRandomVariable(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "# Initialize model and likelihood\n",
    "model = GPClassificationModel(train_x.data)\n",
    "likelihood = BernoulliLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrg365/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/jrg365/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/50 - Loss: 331.950   log_lengthscale: 0.000\n",
      "Iter 2/50 - Loss: 235.139   log_lengthscale: -0.100\n",
      "Iter 3/50 - Loss: 153.589   log_lengthscale: -0.200\n",
      "Iter 4/50 - Loss: 100.220   log_lengthscale: -0.297\n",
      "Iter 5/50 - Loss: 64.491   log_lengthscale: -0.393\n",
      "Iter 6/50 - Loss: 40.145   log_lengthscale: -0.487\n",
      "Iter 7/50 - Loss: 26.331   log_lengthscale: -0.579\n",
      "Iter 8/50 - Loss: 20.038   log_lengthscale: -0.669\n",
      "Iter 9/50 - Loss: 18.432   log_lengthscale: -0.756\n",
      "Iter 10/50 - Loss: 17.716   log_lengthscale: -0.841\n",
      "Iter 11/50 - Loss: 16.808   log_lengthscale: -0.922\n",
      "Iter 12/50 - Loss: 16.033   log_lengthscale: -1.001\n",
      "Iter 13/50 - Loss: 15.583   log_lengthscale: -1.078\n",
      "Iter 14/50 - Loss: 15.100   log_lengthscale: -1.151\n",
      "Iter 15/50 - Loss: 13.901   log_lengthscale: -1.222\n",
      "Iter 16/50 - Loss: 13.329   log_lengthscale: -1.290\n",
      "Iter 17/50 - Loss: 12.991   log_lengthscale: -1.355\n",
      "Iter 18/50 - Loss: 11.378   log_lengthscale: -1.417\n",
      "Iter 19/50 - Loss: 11.357   log_lengthscale: -1.477\n",
      "Iter 20/50 - Loss: 11.265   log_lengthscale: -1.533\n",
      "Iter 21/50 - Loss: 11.437   log_lengthscale: -1.586\n",
      "Iter 22/50 - Loss: 11.040   log_lengthscale: -1.637\n",
      "Iter 23/50 - Loss: 10.637   log_lengthscale: -1.685\n",
      "Iter 24/50 - Loss: 10.994   log_lengthscale: -1.730\n",
      "Iter 25/50 - Loss: 10.630   log_lengthscale: -1.772\n",
      "Iter 26/50 - Loss: 10.869   log_lengthscale: -1.812\n",
      "Iter 27/50 - Loss: 10.542   log_lengthscale: -1.848\n",
      "Iter 28/50 - Loss: 11.525   log_lengthscale: -1.882\n",
      "Iter 29/50 - Loss: 10.654   log_lengthscale: -1.913\n",
      "Iter 30/50 - Loss: 10.722   log_lengthscale: -1.941\n",
      "Iter 31/50 - Loss: 10.852   log_lengthscale: -1.967\n",
      "Iter 32/50 - Loss: 10.890   log_lengthscale: -1.990\n",
      "Iter 33/50 - Loss: 10.829   log_lengthscale: -2.011\n",
      "Iter 34/50 - Loss: 10.913   log_lengthscale: -2.030\n",
      "Iter 35/50 - Loss: 10.907   log_lengthscale: -2.048\n",
      "Iter 36/50 - Loss: 10.370   log_lengthscale: -2.063\n",
      "Iter 37/50 - Loss: 10.894   log_lengthscale: -2.077\n",
      "Iter 38/50 - Loss: 11.042   log_lengthscale: -2.089\n",
      "Iter 39/50 - Loss: 10.673   log_lengthscale: -2.099\n",
      "Iter 40/50 - Loss: 11.016   log_lengthscale: -2.109\n",
      "Iter 41/50 - Loss: 10.697   log_lengthscale: -2.118\n",
      "Iter 42/50 - Loss: 10.646   log_lengthscale: -2.125\n",
      "Iter 43/50 - Loss: 10.749   log_lengthscale: -2.132\n",
      "Iter 44/50 - Loss: 10.735   log_lengthscale: -2.137\n",
      "Iter 45/50 - Loss: 10.588   log_lengthscale: -2.142\n",
      "Iter 46/50 - Loss: 11.001   log_lengthscale: -2.146\n",
      "Iter 47/50 - Loss: 10.955   log_lengthscale: -2.150\n",
      "Iter 48/50 - Loss: 10.553   log_lengthscale: -2.153\n",
      "Iter 49/50 - Loss: 10.828   log_lengthscale: -2.155\n",
      "Iter 50/50 - Loss: 10.421   log_lengthscale: -2.157\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    # BernoulliLikelihood has no parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# n_data refers to the amount of training data\n",
    "mll = gpytorch.mlls.VariationalMarginalLogLikelihood(likelihood, model, n_data=len(train_y))\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0],\n",
    "        model.covar_module.log_lengthscale.data.squeeze()[0],\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAADSCAYAAACo7W6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc367e04550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Go into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize fig and axes for plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "test_x = Variable(torch.linspace(0, 1, 101))\n",
    "## Not sure why this is with... Get Bernoulli prediction\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Plotting function\n",
    "# A lot of this should be consolidated as helper between different notebooks\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    pred_labels = rand_var.mean().ge(0.5).float().mul(2).sub(1)\n",
    "    ax.plot(test_x.data.numpy(), pred_labels.data.numpy(), 'b')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot square wave predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
